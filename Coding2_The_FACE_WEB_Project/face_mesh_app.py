import streamlit as st
#æœºæ¢°å­¦ä¹ ï¼Œmediapipe
import mediapipe as mp
import cv2
import numpy as np
#ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å’Œç›®å½•
import tempfile
import time
#å›¾åƒå¤„ç†Pillow
from PIL import Image

###â¤ï¸â¤ï¸â¤ï¸
import style
import saved_models


mp_drawing = mp.solutions.drawing_utils
mp_face_mesh = mp.solutions.face_mesh

DEMO_IMAGE = 'women.jpg'
DEMO_VIDEO = 'video.mp4'

#ä¸»é¡µæ ‡é¢˜
st.title(' ***THE FACE WEB*** ')

#ä½¿ç”¨htmlçš„å¿…éœ€å“
st.markdown (
    """
    <style>
    [data-testid = "stSidebar"][aria-expanded = "true"] > div:first-child{
        width:350px
    }
    [data-testid = "stSidebar"][aria-expanded = "false"] > div:first-child{
        width:350px
        margin-left : -350px
    }
    </style>
    """,
    unsafe_allow_html=True,
)

#sidebaræ ‡é¢˜
st.sidebar.title("***THE FACE*** Sidebar")
st.sidebar.subheader('Mode selection')


#oen cv å°†ä¿æŒåŸå§‹å›¾åƒçš„çºµæ¨ªæ¯”
@st.cache()
def image_resize(image,width=None,height=None,inter=cv2.INTER_AREA):
    dim = None
    (h,w) = image.shape[:2]

    if width is None and height is None:
        return image
    if width is None:
        r = width/float(w)
        dim = (int(w*r),height)
    else:
        r = width/float(w)
        dim = (width,int(h*r))

    resized = cv2.resize(image,dim,interpolation=inter)

    return resized

#é€‰æ‹©æ¡
app_mode = st.sidebar.selectbox('Choose the App mode',
                                ['Introduction','Image Recognition','Video Recognition','Style Transfer']
                                )


#åœ¨ç®€ä»‹è¿™ä¸€å—
if app_mode == 'Introduction':
    st.subheader('Introductory video')
    st.markdown('The video below describes how to use this website ğŸ‘‡ ')

    # ä½¿ç”¨htmlçš„å¿…éœ€å“
    st.markdown (
        """
        <style>
        [data-testid = "stSidebar"][aria-expanded = "true"] > div:first-child{
            width:350px
        }
        [data-testid = "stSidebar"][aria-expanded = "false"] > div:first-child{
            width:350px
            margin-left : -350px
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.video('https://youtu.be/2u-2UKVB-ws')

    st.subheader('Introduction:')
    st.markdown("""
                
                Welcome to the website of THE FACE WEB. ğŸ˜Š ğŸ˜Š ğŸ˜Š ğŸ‰ ğŸ‰ ğŸ‰ \n
                This Website is created using tools such as opencv, python, PyTorch, streamlit, numpy, and more. \n
                On this Website, there are three different modes.âœŒï¸ âœŒï¸ âœŒï¸ ï¸\n
                ğŸ“· In Image Recognition mode: This is a picture recognition system.You can upload your own images to see the number of faces in the uploaded images. \n
                ğŸ‘€ In Video Recognition Mode: This is a video recognition system where you can upload videos, and the website will recognize the number of faces of people in the video. \n
                ğŸŒ¹ In Style Transfer mode: You can select different pictures about "faces" provided by the system, and then select different styles to convert the pictures. \n
                
                """)


elif app_mode == 'Image Recognition':
    #è„¸ä¸Šè¯†åˆ«çš„çº¿
    drawing_spec = mp_drawing.DrawingSpec(thickness=2,circle_radius=1)

    #sidebar
    st.sidebar.markdown('-------')
    # ä½¿ç”¨htmlçš„å¿…éœ€å“
    st.markdown (
        """
        <style>
        [data-testid = "stSidebar"][aria-expanded = "true"] > div:first-child{
            width:350px
        }
        [data-testid = "stSidebar"][aria-expanded = "false"] > div:first-child{
            width:350px
            margin-left : -350px
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    #æ£€æµ‹åˆ°çš„è„¸çš„æ•°é‡ï¼Œé¢˜ç›®
    st.markdown("***Detected faces***")
    # æ£€æµ‹åˆ°çš„è„¸çš„æ•°é‡ï¼Œæ•°å­—
    kpil_text = st.markdown("0")

    # sidebar
    st.sidebar.subheader('Face Detection Value Adjustments')
    max_faces = st.sidebar.number_input('The Number Of Detected Faces',value= 2,min_value=1)

    detection_confidence = st.sidebar.slider('Min Detection Confidence',min_value=0.0,max_value=1.0,value=0.5)
    st.sidebar.markdown('----')

    #browse å›¾åƒ,åŠ è½½æœ¬åœ°å›¾åƒ
    img_file_buffer = st.sidebar.file_uploader("Upload an Image",type=["jpg","jpeg","png"])
    #æ”¾å›¾åƒ
    if img_file_buffer is not None:
        image = np.array(Image.open(img_file_buffer))
    else:
        demo_image = DEMO_IMAGE
        image = np.array(Image.open(demo_image))

    st.sidebar.text('Original Image')
    st.sidebar.image(image)

    #åˆå§‹åŒ–è„¸çš„ä¸ªæ•°
    face_count = 0

    #dashboard
    with mp_face_mesh.FaceMesh(
    static_image_mode= True,
    max_num_faces=max_faces,
    min_detection_confidence= detection_confidence) as face_mesh:
        results = face_mesh.process(image)
        out_image = image.copy()

        #Face landmark drawing
        for face_landmarks in results.multi_face_landmarks:
            face_count +=1

            mp_drawing.draw_landmarks(
            image = out_image,
            landmark_list= face_landmarks,
            connections = mp_face_mesh.FACEMESH_CONTOURS,
            landmark_drawing_spec = drawing_spec)

            #æ£€æµ‹åˆ°çš„è„¸çš„æ•°é‡ æ•°å­—å†™å…¥
            kpil_text.write(f"<h1 style='text-align:center;color:red;'>{face_count}</h1>",unsafe_allow_html=True)

        #å±•ç¤ºå›¾ç‰‡
        st.subheader('Output Image')
        st.image(out_image,use_column_width=True)



########################video

elif app_mode == 'Video Recognition':

    st.set_option('deprecation.showfileUploaderEncoding', False)
    #ä½¿ç”¨æ‘„åƒå¤´
    st.sidebar.subheader('Webcam Mode')
    use_webcam = st.sidebar.button('Use Webcam')
    st.sidebar.markdown('---')

    # å½•åƒ
    st.sidebar.subheader('Record Video Mode')
    record = st.sidebar.checkbox("Record Video")
    if record:
        st.checkbox("Recording",value=True)
    st.sidebar.markdown('---')

    # ä½¿ç”¨htmlçš„å¿…éœ€å“
    st.markdown (
        """
        <style>
        [data-testid = "stSidebar"][aria-expanded = "true"] > div:first-child{
            width:350px
        }
        [data-testid = "stSidebar"][aria-expanded = "false"] > div:first-child{
            width:350px
            margin-left : -350px
        }
        </style>
        """,
        unsafe_allow_html=True,
    )


    #è®¾ç½®sidebaræ•°å€¼
    st.sidebar.subheader('Face Detection Value Adjustments')
    #æ£€æµ‹è„¸çš„æ•°é‡
    max_faces = st.sidebar.number_input('The Number Of Detected Faces',value= 5, min_value=1)

    detection_confidence = st.sidebar.slider('Min Detection Confidence',min_value=0.0,max_value=1.0,value=0.5)
    tracking_confidence = st.sidebar.slider('Min Tracking Confidence', min_value=0.0, max_value=1.0, value=0.5)
    st.sidebar.markdown('----')


    #é¡µé¢æ˜¾ç¤º
    st.markdown("## Output")

    #åŠ è½½è§†é¢‘
    st.sidebar.subheader('Upload Mode')
    stframe = st.empty()
    video_file_buffer = st.sidebar.file_uploader("Upload a Video",type = ['mp4','mov','avi','asf','m4v'])
    tffile = tempfile.NamedTemporaryFile(delete=False)


    #æ”¾video
    if not video_file_buffer:
        if use_webcam:
            vid = cv2.VideoCapture(0)
        else:
            vid = cv2.VideoCapture(DEMO_VIDEO)
            tffile.name = DEMO_VIDEO
    else:
        tffile.write(video_file_buffer.read())
        vid = cv2.VideoCapture(tffile.name)

    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_input = int(vid.get(cv2.CAP_PROP_FPS))

    #Recording
    codec = cv2.VideoWriter_fourcc('N','J','P','6')
    out = cv2.VideoWriter('output1.mp4',codec,fps_input,(width,height))

    st.sidebar.text('Input Video')
    st.sidebar.video(tffile.name)

    fps = 0
    i = 0

    #ç”»è„¸éƒ¨æ£€æµ‹çš„çº¿
    drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=1)

    #é¡µé¢æ˜¾ç¤ºæ•°å€¼
    kpi1,kpi2,kpi3 = st.columns(3)

    with kpi1:
        st.markdown("**Frame Rate**")
        kpi1_text = st.markdown("0")

    with kpi2:
        st.markdown("**Detected Faces**")
        kpi2_text = st.markdown("0")

    with kpi3:
        st.markdown("**Image Width**")
        kpi3_text = st.markdown("0")

    st.markdown("<hr/>",unsafe_allow_html=True)

    # facemesh predictor
    with mp_face_mesh.FaceMesh(
    max_num_faces=max_faces,
    min_detection_confidence=detection_confidence,
    min_tracking_confidence=tracking_confidence
    ) as face_mesh:
        prevTime = 0

        while vid.isOpened():
            i += 1
            ret,frame = vid.read()
            if not ret:
                continue


            results = face_mesh.process(frame)
            frame.flags.writeable = True


            face_count = 0
            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    face_count += 1

                    mp_drawing.draw_landmarks(
                        image= frame,
                        landmark_list=face_landmarks,
                        connections=mp_face_mesh.FACEMESH_CONTOURS,
                        landmark_drawing_spec=drawing_spec,
                        connection_drawing_spec=drawing_spec)

            currTime = time.time()
            fps = 1/(currTime - prevTime)
            prevTime = currTime

            if record:
                out.write(frame)


            #dashboard
            kpi1_text.write(f"<h1 style='text-align:center;color:red;'>{int(fps)}</h1>", unsafe_allow_html=True)
            kpi2_text.write(f"<h1 style='text-align:center;color:red;'>{face_count}</h1>", unsafe_allow_html=True)
            kpi3_text.write(f"<h1 style='text-align:center;color:red;'>{width}</h1>", unsafe_allow_html=True)

            frame = cv2.resize(frame,(0,0),fx = 0.8,fy=0.8)
            frame = image_resize(image = frame,width = 640)
            stframe.image(frame,channels = "BGR",use_column_width = True)

elif app_mode == 'Style Transfer':
    st.subheader('The Face Style Transfer')
    st.sidebar.markdown('___')
    st.sidebar.subheader('Style Transfer Mode')
    img = st.sidebar.selectbox(
        'Select Image',
        ('women.jpg','women_group.jpg','man.jpg','man_group.jpg','team.jpg')
    )

    style_name = st.sidebar.selectbox(
        'Select Style',
        ('candy', 'mosaic', 'rain_princess', 'udnie')
    )

    model = "saved_models/" + style_name + ".pth"
    input_image = "images/content-images/" + img
    output_image = "images/output-images/" + style_name + "-" + img

    st.write('Source Image:')
    image = Image.open(input_image)
    st.image(image, width=400)  # image: numpy array

    st.markdown('Press the button below to make a picture style transfer ğŸ‘‡ ')

    clicked = st.button('Stylize')

    if clicked:
        model = style.load_model(model)
        style.stylize(model, input_image, output_image)

        st.write('### Output image:')
        image = Image.open(output_image)
        st.image(image, width=400)













